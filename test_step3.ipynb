{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import csv\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data normalization\n",
    "def normalize(data):\n",
    "    data_ = []\n",
    "    for i in range(len(data)):\n",
    "        row = []\n",
    "        for j in range(len(data[i])):\n",
    "            if j == 2:\n",
    "                row.append(int(data[i][j])/12)\n",
    "            elif j == 3:\n",
    "                val = (float(data[i][j]) +60)/60\n",
    "                row.append(val)\n",
    "            elif j == 10:\n",
    "                row.append(int(round(float(data[i][j])))/200)\n",
    "            else:\n",
    "                row.append(float(data[i][j]))\n",
    "        data_.append(row)\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load centroids from step2 clustering results\n",
    "def getCentroids():\n",
    "    cs = []\n",
    "    with open(\"centroids_2.csv\", \"r\") as csvfile:\n",
    "        rows = csv.reader(csvfile)\n",
    "        for row in rows:\n",
    "            drow = []\n",
    "            for col in row:\n",
    "                drow.append(float(col))\n",
    "            cs.append(drow)\n",
    "    #cs = np.array(cs)\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每個sample使用features如下，共11個。\n",
    "#['danceability','energy','key', 'loudness', 'mode', 'speechiness', 'acousticness','instrumentalness',\n",
    "# 'liveness','valence','tempo']\n",
    "#classify a feature vector. x must be a 1x11 vector(11 features)\n",
    "def classify(centroids,x):\n",
    "    minDis = 0\n",
    "    belong = 0\n",
    "    for i in range(len(centroids)):\n",
    "        val = 0\n",
    "        for j in range(len(centroids[0])):\n",
    "            val += math.pow(x[j]-centroids[i][j],2)\n",
    "        if i == 0:\n",
    "            minDis = val\n",
    "        elif val < minDis:\n",
    "            minDis = val\n",
    "            belong = i\n",
    "    return belong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataClusters(data):\n",
    "    #load pca model from step2\n",
    "    pca = load(\"pca.joblib\")\n",
    "    \n",
    "    #get centroids from reord\n",
    "    centroids = getCentroids()\n",
    "    clusterAmount = len(centroids)\n",
    "    #noramlize data\n",
    "    data = normalize(data)\n",
    "    \n",
    "    #transform data with pca model\n",
    "    data = np.array(data, dtype=float)\n",
    "    data = pca.transform(data)\n",
    "    \n",
    "    #cluster stats\n",
    "    nums = []\n",
    "    for i in range(clusterAmount):\n",
    "        nums.append(0)\n",
    "    \n",
    "    #classify every sample in data and output nums of each class\n",
    "    clus = []\n",
    "    for i in range(len(data)):\n",
    "        label = classify(centroids, data[i])\n",
    "        clus.append(label)\n",
    "        nums[label]+=1\n",
    "        \n",
    "    return clus, nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "test_x = []\n",
    "#set dataset path:\n",
    "path = \"../playlistresult.csv\"\n",
    "#header = []\n",
    "with open(path, \"r\") as csvfile:\n",
    "    rows = csv.reader(csvfile)\n",
    "    for row in rows:\n",
    "        test_x.append(row[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y, test_y_stats = getDataClusters(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 3, 4, 8, 7, 9, 8, 0, 0]\n",
      "[13, 7, 2, 8, 8, 3, 5, 5, 4, 7, 11, 8, 5, 4, 10]\n"
     ]
    }
   ],
   "source": [
    "print(test_y[:10])\n",
    "print(test_y_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
